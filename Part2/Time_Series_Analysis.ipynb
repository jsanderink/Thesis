{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db744fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module://matplotlib_inline.backend_inline\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import functions as fx\n",
    "import numpy as np\n",
    "import researchpy as rp\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "\n",
    "import inspect\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f3830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = pd.read_csv(\"export_student_sessions.csv\", delimiter=';')\n",
    "switched = pd.read_csv(\"export_level_switched_log.csv\", delimiter=';')\n",
    "students = pd.read_csv(\"export_students.csv\", delimiter=';')\n",
    "users = pd.read_csv(\"export_users.csv\", delimiter=';')\n",
    "students_filtered = pd.read_csv(\"students_filtered.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ef20d",
   "metadata": {},
   "source": [
    "## Put the sessions of the students in the timeframe in one dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1077acfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671, 11) (325, 11)\n",
      "(325, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>interval</th>\n",
       "      <th>stars</th>\n",
       "      <th>score</th>\n",
       "      <th>clippy</th>\n",
       "      <th>block_try_counter</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>student_id</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-21 10:28:24</td>\n",
       "      <td>35457.738095</td>\n",
       "      <td>41.124648</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.611454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.162308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227b548a-4e80-4333-9fd8-f783c577475e</td>\n",
       "      <td>2021-10-21 10:28:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-10-21 08:17:55</td>\n",
       "      <td>34250.678788</td>\n",
       "      <td>44.721962</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.833722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ace9664f-f79c-411d-87d3-4aeaf3962ffb</td>\n",
       "      <td>2021-10-21 08:17:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-11-03 18:40:42</td>\n",
       "      <td>131089.000000</td>\n",
       "      <td>103.352941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ace9664f-f79c-411d-87d3-4aeaf3962ffb</td>\n",
       "      <td>2021-11-03 18:40:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-11-04 09:22:00</td>\n",
       "      <td>150719.172619</td>\n",
       "      <td>83.993860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ace9664f-f79c-411d-87d3-4aeaf3962ffb</td>\n",
       "      <td>2021-11-04 09:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-11-03 20:50:29</td>\n",
       "      <td>141693.594595</td>\n",
       "      <td>12.076923</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.497222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e2179d2e-8989-4f3d-943b-1c7435a6daa6</td>\n",
       "      <td>2021-11-03 20:50:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2021-11-12 13:11:26</td>\n",
       "      <td>203822.000000</td>\n",
       "      <td>58.570261</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.612302</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a6bda0a3-f162-47d1-9ec7-ef697a014278</td>\n",
       "      <td>2021-11-12 13:11:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2021-11-12 13:26:56</td>\n",
       "      <td>206940.553366</td>\n",
       "      <td>36.853405</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.668499</td>\n",
       "      <td>0.039737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a6bda0a3-f162-47d1-9ec7-ef697a014278</td>\n",
       "      <td>2021-11-12 13:26:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>2021-11-12 13:14:13</td>\n",
       "      <td>203826.500000</td>\n",
       "      <td>77.342857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.542604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.171429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>838c4e69-f68b-47d3-aa07-48e2f4b3f721</td>\n",
       "      <td>2021-11-12 13:14:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>2021-11-12 13:35:38</td>\n",
       "      <td>206948.575480</td>\n",
       "      <td>54.757823</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.677629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.059957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>838c4e69-f68b-47d3-aa07-48e2f4b3f721</td>\n",
       "      <td>2021-11-12 13:35:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>2021-11-16 21:09:04</td>\n",
       "      <td>243745.400000</td>\n",
       "      <td>35.970390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.648730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.081645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0e6aae90-c30f-4754-8119-8d68da178c4a</td>\n",
       "      <td>2021-11-16 21:09:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp             id    interval     stars     score  \\\n",
       "1    2021-10-21 10:28:24   35457.738095   41.124648  0.001942  0.611454   \n",
       "8    2021-10-21 08:17:55   34250.678788   44.721962  3.000000  0.833722   \n",
       "9    2021-11-03 18:40:42  131089.000000  103.352941  0.000000  0.750000   \n",
       "10   2021-11-04 09:22:00  150719.172619   83.993860  0.000000  0.558061   \n",
       "13   2021-11-03 20:50:29  141693.594595   12.076923  2.000000  0.497222   \n",
       "..                   ...            ...         ...       ...       ...   \n",
       "666  2021-11-12 13:11:26  203822.000000   58.570261  2.000000  0.612302   \n",
       "667  2021-11-12 13:26:56  206940.553366   36.853405  0.016260  0.668499   \n",
       "668  2021-11-12 13:14:13  203826.500000   77.342857  1.000000  0.542604   \n",
       "669  2021-11-12 13:35:38  206948.575480   54.757823  0.500000  0.677629   \n",
       "670  2021-11-16 21:09:04  243745.400000   35.970390  1.000000  0.648730   \n",
       "\n",
       "       clippy  block_try_counter  created_at  updated_at  \\\n",
       "1    0.000000           1.162308         NaN         NaN   \n",
       "8    0.000000           1.000000         NaN         NaN   \n",
       "9    0.000000           1.000000         NaN         NaN   \n",
       "10   0.000000           1.000000         NaN         NaN   \n",
       "13   0.000000           1.153846         NaN         NaN   \n",
       "..        ...                ...         ...         ...   \n",
       "666  0.041667           1.000000         NaN         NaN   \n",
       "667  0.039737           1.000000         NaN         NaN   \n",
       "668  0.000000           1.171429         NaN         NaN   \n",
       "669  0.000000           1.059957         NaN         NaN   \n",
       "670  0.000000           1.081645         NaN         NaN   \n",
       "\n",
       "                               student_id            datetime  \n",
       "1    227b548a-4e80-4333-9fd8-f783c577475e 2021-10-21 10:28:24  \n",
       "8    ace9664f-f79c-411d-87d3-4aeaf3962ffb 2021-10-21 08:17:55  \n",
       "9    ace9664f-f79c-411d-87d3-4aeaf3962ffb 2021-11-03 18:40:42  \n",
       "10   ace9664f-f79c-411d-87d3-4aeaf3962ffb 2021-11-04 09:22:00  \n",
       "13   e2179d2e-8989-4f3d-943b-1c7435a6daa6 2021-11-03 20:50:29  \n",
       "..                                    ...                 ...  \n",
       "666  a6bda0a3-f162-47d1-9ec7-ef697a014278 2021-11-12 13:11:26  \n",
       "667  a6bda0a3-f162-47d1-9ec7-ef697a014278 2021-11-12 13:26:56  \n",
       "668  838c4e69-f68b-47d3-aa07-48e2f4b3f721 2021-11-12 13:14:13  \n",
       "669  838c4e69-f68b-47d3-aa07-48e2f4b3f721 2021-11-12 13:35:38  \n",
       "670  0e6aae90-c30f-4754-8119-8d68da178c4a 2021-11-16 21:09:04  \n",
       "\n",
       "[325 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def str_to_datetime(string):\n",
    "    return datetime.strptime(string, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "sessions\n",
    "sessions_2 = pd.DataFrame(columns=['timestamp','id','interval','stars','score','clippy','block_try_counter','student_id','datetime'])\n",
    "participating_students = sessions[sessions['student_id'].isin(students_filtered['user_id'])]\n",
    "\n",
    "for stu_id in participating_students['student_id'].unique():\n",
    "    # take mean of all sessions on same date and time\n",
    "    sessions_student_x = participating_students[participating_students['student_id']==stu_id].groupby('timestamp').mean()\n",
    "    # .groupby() takes away the student id, get it back. \n",
    "    sessions_student_x['student_id'] = stu_id\n",
    "    #make the index a column in the dataframe\n",
    "    sessions_student_x.reset_index(level=0, inplace=True)\n",
    "    #give a datetime variable\n",
    "    sessions_student_x['datetime'] = sessions_student_x['timestamp'].apply(str_to_datetime)\n",
    "    \n",
    "    sessions_2 = pd.merge(sessions_2,\n",
    "                    sessions_student_x,\n",
    "                    how='outer')\n",
    "    \n",
    "cutoff = str_to_datetime(\"2021-10-20 13:00:00\")\n",
    "cutoff\n",
    "\n",
    "# Keep only rows with a datetime after the start of the experiment (2021-10-20 13:00:00)\n",
    "sessions_to_analyze = sessions_2[sessions_2['datetime']>cutoff]\n",
    "print(sessions_2.shape, sessions_to_analyze.shape)\n",
    "\n",
    "# sessions_to_analyze\n",
    "print(sessions_to_analyze.shape)\n",
    "\n",
    "sessions_to_analyze.to_csv(\"sessions_to_analyze.csv\", sep=';')\n",
    "\n",
    "\n",
    "sessions_to_analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5e4405",
   "metadata": {},
   "source": [
    "# Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff405ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 188 students in the data that had at least 1 session during the experimental period\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} students in the data that had at least 1 session during the experimental period\".format(sessions_to_analyze['student_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d198b25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>from_level</th>\n",
       "      <th>to_level</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>from_no</th>\n",
       "      <th>to_no</th>\n",
       "      <th>up_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146</td>\n",
       "      <td>147</td>\n",
       "      <td>e5a00790-10d0-4e79-ba66-d9e8836e12ac</td>\n",
       "      <td>VMBO_HAVO</td>\n",
       "      <td>HAVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147</td>\n",
       "      <td>148</td>\n",
       "      <td>ff0bfe14-f346-4af8-958a-0debdd764cf4</td>\n",
       "      <td>VMBOK</td>\n",
       "      <td>VMBO_HAVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148</td>\n",
       "      <td>149</td>\n",
       "      <td>c3077517-cd98-4b76-801c-eb63ea574305</td>\n",
       "      <td>VMBOK</td>\n",
       "      <td>VMBO_HAVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>142f73ec-66b6-461f-83fe-948e4ed37bc7</td>\n",
       "      <td>VMBOK</td>\n",
       "      <td>VMBO_HAVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>10d31ad6-94e2-4115-92b8-f399cd7497b7</td>\n",
       "      <td>VMBOK</td>\n",
       "      <td>VMBO_HAVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   id                               user_id from_level   to_level  \\\n",
       "0    146  147  e5a00790-10d0-4e79-ba66-d9e8836e12ac  VMBO_HAVO       HAVO   \n",
       "1    147  148  ff0bfe14-f346-4af8-958a-0debdd764cf4      VMBOK  VMBO_HAVO   \n",
       "2    148  149  c3077517-cd98-4b76-801c-eb63ea574305      VMBOK  VMBO_HAVO   \n",
       "3    149  150  142f73ec-66b6-461f-83fe-948e4ed37bc7      VMBOK  VMBO_HAVO   \n",
       "4    150  151  10d31ad6-94e2-4115-92b8-f399cd7497b7      VMBOK  VMBO_HAVO   \n",
       "\n",
       "   created_at  updated_at  from_no  to_no  up_down  \n",
       "0         NaN         NaN        3      4        1  \n",
       "1         NaN         NaN        2      3        1  \n",
       "2         NaN         NaN        2      3        1  \n",
       "3         NaN         NaN        2      3        1  \n",
       "4         NaN         NaN        2      3        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def txt_to_lvl(txt):\n",
    "    return {'GYMNASIUM':6, 'HAVO':4, 'HAVO_VWO':5, 'VMBOK':2, 'VMBO_HAVO':3}[txt]\n",
    "\n",
    "switched.head()\n",
    "# the initialization is also already in this dataframe\n",
    "# Drop all the initial switches and keep only switches that happened during the experiment (non-startup phase)\n",
    "real_switched = switched[switched['from_level'].isin(list(switched['from_level'].value_counts().keys()))].reset_index()\n",
    "\n",
    "real_switched[\"from_no\"] = real_switched['from_level'].map(txt_to_lvl)\n",
    "real_switched[\"to_no\"] = real_switched['to_level'].map(txt_to_lvl)\n",
    "\n",
    "# Indicating if the switch was up or down\n",
    "updown = []\n",
    "for row in real_switched.iterrows():\n",
    "    if txt_to_lvl(row[1]['from_level'])<txt_to_lvl(row[1]['to_level']):\n",
    "        switch = 1\n",
    "    elif txt_to_lvl(row[1]['from_level'])>txt_to_lvl(row[1]['to_level']):\n",
    "        switch = -1\n",
    "    else:\n",
    "        print(\"ERRROR\")\n",
    "    updown.append(switch)\n",
    "    \n",
    "# The lowest 'from_no'  is the initial level of the student\n",
    "initial_lvl = {uid:real_switched[real_switched['user_id']==uid]['from_no'].min() for uid in list(set(real_switched['user_id']))}\n",
    "\n",
    "real_switched['up_down'] = updown\n",
    "real_switched.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a956c669",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'switched_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19952/1720058134.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mswitched_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mstudent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreal_switched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreal_switched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0msid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mstudent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'from_no'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'switched_ids' is not defined"
     ]
    }
   ],
   "source": [
    "for sid in switched_ids:\n",
    "    student = real_switched[real_switched['user_id']==sid].reset_index()\n",
    "    if len(student) > 6:\n",
    "        student['from_no'].plot()\n",
    "\n",
    "    plt.title(\"Level of Switched Students\")\n",
    "    plt.ylim(0,7)\n",
    "    plt.xlabel('Number of Switch')\n",
    "    plt.ylabel('Level of Difficulty')\n",
    "plt.grid(which='major')    \n",
    "# plt.legend()\n",
    "plt.savefig('students_switching_levels.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f75c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid in switched_ids:\n",
    "    student = real_switched[real_switched['user_id']==sid].reset_index()\n",
    "    if len(student) == 6:\n",
    "        student['from_no'].plot()\n",
    "\n",
    "    plt.title(\"Calculation of slopes (grey lines are sessions)\")\n",
    "    plt.ylim(0,7)\n",
    "    plt.xlabel('Number of Switch')\n",
    "    plt.ylabel('Level of Difficulty')\n",
    "    plt.vlines(x=[i*(6/8) for i in range(7)], ymin=0, ymax=7, linestyles='dashed', colors='grey')\n",
    "plt.grid(which='major')    \n",
    "# plt.legend()\n",
    "plt.savefig('explain_slope_without_paint.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need a counter of the i-th session after a switch \n",
    "# and what the level is relative to the initial level\n",
    "sessions = sessions_to_analyze.sort_values(by=['student_id', \"timestamp\"]).reset_index()\n",
    "sessions\n",
    "\n",
    "# Now i am going to make a counter of the I-th session of a student\n",
    "sess_no = 1\n",
    "sess_list = [1]\n",
    "\n",
    "for idx in range(1,len(sessions['student_id'])):\n",
    "    if sessions['student_id'][idx-1]==sessions['student_id'][idx]:\n",
    "        sess_no +=1\n",
    "    elif sessions['student_id'][idx-1]!=sessions['student_id'][idx]:\n",
    "        sess_no = 1\n",
    "    sess_list.append(sess_no)   \n",
    "sessions['session_number'] = sess_list\n",
    "\n",
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dfe587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell i need to make the switched counters\n",
    "sessions[sessions['student_id']=='00cdcdce-737d-4511-b48b-69c0102b7b37']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92391188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting up in control/experiment and switched/not_switched\n",
    "\n",
    "# student IDs from the control group (=1):\n",
    "control_ids = list(students_filtered[students_filtered['use_adaptive_academic_level']==1]['user_id'])\n",
    "# student IDs from the experimental group (=2):\n",
    "experimental_ids = list(students_filtered[students_filtered['use_adaptive_academic_level']==2]['user_id'])\n",
    "# student IDs from the students who switched:\n",
    "switched_ids = list(real_switched['user_id'].unique())\n",
    "# student IDs from the students who did not switch:\n",
    "not_switched_ids = control_ids+(list(set(experimental_ids)-set(switched_ids)))\n",
    "\n",
    "control_df = sessions[sessions['student_id'].isin(control_ids)]\n",
    "experimental_df = sessions[sessions['student_id'].isin(experimental_ids)]\n",
    "\n",
    "switched_df = sessions[sessions['student_id'].isin(switched_ids)]\n",
    "not_switched_df = sessions[sessions['student_id'].isin(not_switched_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca9e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both partitions contain all the 325 sessions\n",
    "print(len(control_df)+len(experimental_df)), print(len(switched_df)+len(not_switched_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddea5ed",
   "metadata": {},
   "source": [
    "## Making plots to visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003b4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 2, figsize=(10, 10), sharex=True)\n",
    "\n",
    "fig.suptitle('Development of variables over the sessions', fontsize=20)\n",
    "axes[0,0].set_title(\"Switched students\",fontsize=15)\n",
    "axes[0,1].set_title(\"Not switched students\",fontsize=15)\n",
    "\n",
    "sns.boxplot(ax=axes[0,0], data=switched_df, x='session_number', y='interval')\n",
    "sns.boxplot(ax=axes[0,1], data=not_switched_df, x='session_number', y='interval')\n",
    "\n",
    "sns.boxplot(ax=axes[1,0], data=switched_df, x='session_number', y='stars')\n",
    "sns.boxplot(ax=axes[1,1], data=not_switched_df, x='session_number', y='stars')\n",
    "\n",
    "sns.boxplot(ax=axes[2,0], data=switched_df, x='session_number', y='score')\n",
    "sns.boxplot(ax=axes[2,1], data=not_switched_df, x='session_number', y='score')\n",
    "\n",
    "sns.boxplot(ax=axes[3,0], data=switched_df, x='session_number', y='clippy')\n",
    "sns.boxplot(ax=axes[3,1], data=not_switched_df, x='session_number', y='clippy')\n",
    "\n",
    "sns.boxplot(ax=axes[4,0], data=switched_df, x='session_number', y='block_try_counter')\n",
    "sns.boxplot(ax=axes[4,1], data=not_switched_df, x='session_number', y='block_try_counter')\n",
    "\n",
    "fig.savefig('SNS_per_variable.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, figsize=(10,10), sharex=True)\n",
    "\n",
    "red_patch = mpatches.Patch(color='red', label='Not Switched')\n",
    "blue_patch = mpatches.Patch(color='tab:blue', label='Switched')\n",
    "\n",
    "axes[0].legend(handles=[red_patch, blue_patch])\n",
    "\n",
    "axes[0].tick_params(axis='both', which='both', labelbottom=True)\n",
    "axes[1].tick_params(axis='both', which='both', labelbottom=True)\n",
    "axes[2].tick_params(axis='both', which='both', labelbottom=True)\n",
    "axes[3].tick_params(axis='both', which='both', labelbottom=True)\n",
    "axes[4].tick_params(axis='both', which='both', labelbottom=True)\n",
    "\n",
    "y = 'interval'\n",
    "sns.pointplot(data=switched_df, x='session_number', y=y, ax=axes[0])\n",
    "sns.pointplot(data=not_switched_df, x='session_number', y=y,color='red', ax=axes[0])\n",
    "\n",
    "y = 'stars'\n",
    "sns.pointplot(data=switched_df, x='session_number', y=y,ax=axes[1])\n",
    "sns.pointplot(data=not_switched_df, x='session_number', y=y,color='red', ax=axes[1])\n",
    "\n",
    "y = 'score'\n",
    "sns.pointplot(data=switched_df, x='session_number', y=y,  ax=axes[2])\n",
    "sns.pointplot(data=not_switched_df, x='session_number', y=y,color='red', ax=axes[2])\n",
    "\n",
    "y = 'clippy'\n",
    "sns.pointplot(data=switched_df, x='session_number', y=y, ax=axes[3])\n",
    "sns.pointplot(data=not_switched_df, x='session_number', y=y,color='red', ax=axes[3])\n",
    "\n",
    "y = 'block_try_counter'\n",
    "sns.pointplot(data=switched_df, x='session_number', y=y, ax=axes[4]).set_label('Test')\n",
    "sns.pointplot(data=not_switched_df, x='session_number', y=y,color='red',ax=axes[4])\n",
    "\n",
    "fig.savefig('SNS_per_variable.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fccd4e",
   "metadata": {},
   "source": [
    "# Checking the overlap between switches and all sessions of the switched students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the sessions of students that have switched\n",
    "switched_df\n",
    "\n",
    "# These are the switches that these students have made\n",
    "real_switches = real_switched[real_switched['user_id'].isin(switched_df['student_id'])]\n",
    "real_switches['up_down'].value_counts()\n",
    "\n",
    "# Apparently, there are more students that have made switches than that are in the dataset with switches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce3ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gradients(stud_x,y,n, if_one):\n",
    "        slopes = []\n",
    "        if min(n,len(stud_x)) == 0:\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            parts = np.array_split(stud_x, min((n),len(stud_x)))\n",
    "            for i in range(min(len(parts),n)):\n",
    "                if list(parts[i])==[]:\n",
    "                    break\n",
    "                levels = [y[level] for level in parts[i]]\n",
    "                slope = round((levels[-1]-levels[0])/len(levels),2)\n",
    "                slopes.append(slope)\n",
    "        while len(slopes)<n:\n",
    "            slopes.append(0.0)\n",
    "        return slopes\n",
    "\n",
    "gradients = []\n",
    "\n",
    "for sid in switched_ids:\n",
    "    \n",
    "    stud_x = real_switches[real_switches.user_id==sid].reset_index()\n",
    "    \n",
    "    sess_stud_x = switched_df[switched_df['student_id']==sid]\n",
    "    sess_stud_x\n",
    "\n",
    "    stud_x.index\n",
    "    stud_x.from_no  \n",
    "    \n",
    "    if len(stud_x): \n",
    "        if_one=stud_x['up_down'].iloc[0]\n",
    "    else:\n",
    "        if_one = 0\n",
    "    gradients.append(find_gradients(stud_x.index,stud_x.from_no,len(sess_stud_x),if_one))\n",
    "    \n",
    "\n",
    "\n",
    "switched_df['slopes'] = [item for sublist in gradients for item in sublist]\n",
    "switched_df['slopes'].plot()\n",
    "\n",
    "switched_df.sort_values(by=['student_id','datetime'])\n",
    "switched_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fe77bf",
   "metadata": {},
   "source": [
    "# Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab57ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid in switched_ids:\n",
    "    student = switched_df[switched_df['student_id']==sid].reset_index()\n",
    "    if len(student) > 1:\n",
    "        student['stars'].plot()\n",
    "    plt.title(\"stars of Switched Students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a3072",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid in switched_ids:\n",
    "    student = switched_df[switched_df['student_id']==sid].reset_index()\n",
    "    if len(student) > 1:\n",
    "        student['score'].plot()\n",
    "    plt.title(\"Score of Switched Students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22690c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid in switched_ids:\n",
    "    student = switched_df[switched_df['student_id']==sid].reset_index()\n",
    "    if len(student) > 1:\n",
    "        student['clippy'].plot()\n",
    "    plt.title(\"Hints of Switched Students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a6c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid in switched_ids:\n",
    "    student = switched_df[switched_df['student_id']==sid].reset_index()\n",
    "    if len(student) > 1:\n",
    "        student['block_try_counter'].plot()\n",
    "    plt.title(\"Tries of Switched Students\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b61dc",
   "metadata": {},
   "source": [
    "##  Correlation Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc12adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "switched_df[[\"interval\",\"stars\",\"score\",\"clippy\",\"block_try_counter\"]].corr().replace(1,np.nan).style.background_gradient(cmap='Blues')\n",
    "\n",
    "print(switched_df[[\"interval\",\"stars\",\"score\",\"clippy\",\"block_try_counter\"]].corr().replace(1,np.nan).round(decimals=3).to_latex())\n",
    "\n",
    "X = switched_df[[\"interval\",\"stars\",\"score\",\"clippy\",\"block_try_counter\"]].dropna()\n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [round(variance_inflation_factor(X.values, i),2)\n",
    "                          for i in range(len(X.columns))]\n",
    "  \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c578acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_switched_df[[\"interval\",\"stars\",\"score\",\"clippy\",\"block_try_counter\"]].corr().replace(1,np.nan).style.background_gradient(cmap='Blues')\n",
    "\n",
    "print(not_switched_df[[\"interval\",\"stars\",\"score\",\"clippy\",\"block_try_counter\"]].corr().replace(1,np.nan).round(decimals=3).to_latex())\n",
    "\n",
    "X = not_switched_df[[\"interval\",\"stars\",\"score\",\"clippy\",\"block_try_counter\"]].dropna()\n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [round(variance_inflation_factor(X.values, i),2)\n",
    "                          for i in range(len(X.columns))]\n",
    "  \n",
    "print(vif_data['VIF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58955bdd",
   "metadata": {},
   "source": [
    "## DF is in the right format, now going to perform the MLRegressions\n",
    "https://www.pythonfordatascience.org/mixed-effects-regression-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_switched_df['slopes'] = 0;\n",
    "switched_df.columns\n",
    "switched_df['group'] = 1\n",
    "not_switched_df['group']= 0\n",
    "all_sessions = pd.concat([switched_df,not_switched_df], axis=0).fillna(0)\n",
    "all_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions['session_number'].value_counts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4325f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386211b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual indication of how the sessions are divided\n",
    "print(\"group 1 is switched and group 0 is not switched \\n X-axis is the slope indicating a higher/lower difficulty for the student\")\n",
    "all_sessions.plot.scatter('slopes','interval', c='group', cmap='bwr')\n",
    "all_sessions.plot.scatter('slopes','stars', c='group', cmap='bwr')\n",
    "all_sessions.plot.scatter('slopes','score', c='group', cmap='bwr')\n",
    "all_sessions.plot.scatter('slopes','clippy', c='group', cmap='bwr')\n",
    "all_sessions.plot.scatter('slopes','block_try_counter', c='group', cmap='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary(var, df):\n",
    "    # Now to take a look at the interval of the students based on the group and the slopes.\n",
    "    df = rp.summary_cont(df.groupby([\"group\", \"slopes\"])[var])\n",
    "    print(df.to_latex())\n",
    "    return df\n",
    "\n",
    "def viz_distributions(var, df):\n",
    "    \"\"\"visualize the distributions in a boxplot\"\"\"\n",
    "    # Lets visualize the distribution of interval by group and slope\n",
    "    boxplot = df.boxplot([var],by=['group','slopes'],\n",
    "                         figsize = (9, 9),\n",
    "                         showmeans = True,\n",
    "                         notch = True)\n",
    "    boxplot.figure.savefig(\"{}_boxplot.png\".format(var))\n",
    "\n",
    "def fit_model(var, df):\n",
    "    # Now fit a random intercept model, \n",
    "    # recall that this type of model allows for different clusters (a group) to have different intercepts\n",
    "\n",
    "    # the vc_formula is the formula for the variance components, this is used because the slopes are uncorrelated to the \n",
    "    # intercepts\n",
    "    md = smf.mixedlm(\"{} ~ C(group)+session_number+slopes\".format(var),\n",
    "                     df,\n",
    "                     groups=df['student_id'],\n",
    "                    vc_formula = {'group':\"0+C(group)\"}).fit()\n",
    "\n",
    "    print(md.summary())\n",
    "    return md\n",
    "\n",
    "def check_normality(md):\n",
    "    # Lets check for normality \n",
    "    fig,(ax1,ax2) = plt.subplots(2,figsize = (9, 9))\n",
    "    sns.distplot(md.resid, hist = False, kde_kws={'shade':True, 'lw':1}, fit=stats.norm,ax=ax1)\n",
    "    ax1.set_title(\"KDE Plot of Model Residuals (Blue) and Normal Distribution (Black)\")\n",
    "    ax1.set_xlabel(\"Residuals\")\n",
    "\n",
    "    ## Q-Q PLot\n",
    "    fig = plt.figure(figsize = (16, 9))\n",
    "    sm.qqplot(md.resid, dist = stats.norm, line = 's', ax = ax2)\n",
    "    ax2.set_title(\"Q-Q Plot\")\n",
    "\n",
    "    # SK-test for normality\n",
    "    labels = [\"Statistic (SK-test)\", \"p-value\"]\n",
    "    norm_res = stats.shapiro(md.resid)\n",
    "\n",
    "    for key, val in dict(zip(labels, norm_res)).items():\n",
    "        print(key, val)\n",
    "    if norm_res[1]<0.05:\n",
    "        print(\"the test is significant thus normality of residuals is violated\")\n",
    "    else:\n",
    "        print('the test is non-significant thus normality of residuals is supported')\n",
    "        \n",
    "def check_homoskedasticity(md):\n",
    "    # Lets check for homoskedasticity\n",
    "    fig, (ax1,ax2) = plt.subplots(2,figsize = (9, 9))\n",
    "\n",
    "    sns.scatterplot(y = md.resid, x = md.fittedvalues,ax=ax1)\n",
    "\n",
    "    ax1.set_title(\"RVF Plot\")\n",
    "    ax1.set_xlabel(\"Fitted Values\")\n",
    "    ax1.set_ylabel(\"Residuals\")\n",
    "\n",
    "    fig = plt.figure(figsize = (16, 9))\n",
    "\n",
    "    sns.boxplot(x = md.model.groups, y = md.resid, ax=ax2)\n",
    "\n",
    "    ax2.set_title(\"Distribution of Residuals for Interval by student\")\n",
    "    ax2.set_ylabel(\"Residuals\")\n",
    "    ax2.set_xlabel(\"Student\")\n",
    "\n",
    "    het_white_res = het_white(md.resid, md.model.exog)\n",
    "\n",
    "    labels = [\"LM Statistic\", \"LM-Test p-value\", \"F-Statistic\", \"F-Test p-value\"]\n",
    "\n",
    "    for key, val in dict(zip(labels, het_white_res)).items():\n",
    "        print(key, val)\n",
    "        \n",
    "def run_analysis(var, df):\n",
    "    print(show_summary(var, df))\n",
    "    viz_distributions(var, df)\n",
    "    print('\\n')\n",
    "    md = fit_model(var, df)\n",
    "    check_normality(md)\n",
    "    print('\\n')\n",
    "    check_homoskedasticity(md)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6fc018",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3186e31d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "variables = ['interval','score','stars','block_try_counter','clippy']\n",
    "\n",
    "for var in variables:\n",
    "    print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\\n\",var)\n",
    "    md = fit_model(var, all_sessions)\n",
    "#     print(md.summary().as_latex())\n",
    "#     print(type(md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d17f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions.student_id.value_counts().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a89e18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_analysis('interval', all_sessions)\n",
    "# Assumptions violated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f08c84c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_analysis('score', all_sessions)\n",
    "# Assumptions violated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a7788",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_analysis('clippy', all_sessions)\n",
    "# Assumptions violated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b13894",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_analysis('stars', all_sessions)\n",
    "# Assumptions violated\n",
    "# Looks like a Chi-Square Distribution --> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecef1d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_analysis('block_try_counter', all_sessions)\n",
    "# Assumptions violated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3026a380",
   "metadata": {},
   "source": [
    "## normality and homoskedasticity is rejected in all variables\n",
    "I suspect that this happens because there are a lot of students that have a too little sessions in this data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ad852",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# See how much students there are with multiple sessions:\n",
    "all_sessions.student_id.value_counts().value_counts()\n",
    "\n",
    "# These are the students with more than 3 sessions in the experimental period:\n",
    "oft_switch_ids = [sid for sid in  all_sessions.student_id.value_counts().keys() if all_sessions.student_id.value_counts()[sid] > 2]\n",
    "print(\"there are {} students in the dataset with 3 or more sessions\".format(len(oft_switch_ids)))\n",
    "\n",
    "# This is a dataframe where the students with more than 3 sessions are in \n",
    "mult_switch  = all_sessions[all_sessions.student_id.isin(oft_switch_ids)]\n",
    "\n",
    "# The switched sessions (60) and non switched sessions (50) are nicely divided\n",
    "mult_switch.group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482c73a",
   "metadata": {},
   "source": [
    "## Lets run the analysis on students that have 3 or more sessions in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c377dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_analysis('interval',mult_switch)\n",
    "# Assumptions violated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fdd84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_analysis('score',mult_switch)\n",
    "# Here, the data seems good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d329448",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_analysis('stars',mult_switch)\n",
    "# Assumptions violatedv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12dcf97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_analysis('block_try_counter',mult_switch)\n",
    "# Assumptions violated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c05485",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_analysis('clippy',mult_switch)\n",
    "# Assumptions violated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610956c",
   "metadata": {},
   "source": [
    "## I was wrong, there is insufficient data when filtering on students that only have 3 or more sessions.\n",
    "This could be due to a sampling error or insufficient data\n",
    "\n",
    "#### Conclusion\n",
    "without the outliers, with the sqrt of score, and the central limit theorem i get the best results:\n",
    "\n",
    "https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_probability/BS704_Probability12.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b2f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions[variables]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98594adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to remove all 'outliers' that er further than 2 SDs from the mean (within th =95% interval)\n",
    "without_outliers = all_sessions[(np.abs(stats.zscore(all_sessions[variables])) < 2).all(axis=1)]\n",
    "# These seem to be a bit better, nevertheless all are violated (but in the order of .02 or .03 instead of 10^-6)\n",
    "# Here the values are close to normality but since the sample size is quite small, i rely on the central limit theorem (not a \n",
    "# strong argument but one that holds)\n",
    "\n",
    "# https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_probability/BS704_Probability12.html\n",
    "\n",
    "without_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb210172",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run_analysis('interval', without_outliers)\n",
    "# Trying with log/sqrt/reciprocal transformation ==> did not work\n",
    "# without_outliers['log_int'] = without_outliers['interval'].apply(np.reciprocal)\n",
    "# run_analysis('log_int', without_outliers)\n",
    "\n",
    "# Keeping the normal interval variable and stick with it\n",
    "run_analysis('interval', without_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed662f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run_analysis('score', without_outliers)\n",
    "\n",
    "# Trying with log/sqrt/reciprocal transformation ==> sqrt is best!\n",
    "without_outliers['sqrt_score'] = without_outliers['score'].apply(np.sqrt)\n",
    "run_analysis('sqrt_score', without_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae88619",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_analysis('stars', without_outliers)\n",
    "\n",
    "# Trying with log/sqrt/reciprocal transformation ==> is not going to work, sticking with the original\n",
    "# without_outliers['log_stars'] = without_outliers['stars'].apply(np.reciprocal)\n",
    "# run_analysis('log_stars', without_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5d295",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_analysis('block_try_counter', without_outliers)\n",
    "\n",
    "# Trying with log/sqrt/reciprocal transformation ==> is not going to work, sticking with the original\n",
    "# without_outliers['log_btc'] = without_outliers['block_try_counter'].apply(np.log)\n",
    "# run_analysis('log_btc', without_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf8ecb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_analysis('clippy', without_outliers)\n",
    "\n",
    "# Trying with log/sqrt/reciprocal transformation ==> is not going to work, sticking with the original\n",
    "# without_outliers['log_clippy'] = without_outliers['clippy'].apply(np.reciprocal)\n",
    "# run_analysis('log_clippy', without_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5183bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e3a316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae673e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba1c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
